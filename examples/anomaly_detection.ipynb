{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuSc Zero-Shot Anomaly Detection Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the MuSc algorithm for zero-shot industrial anomaly detection.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Loading and configuring the MuSc model\n",
    "- Processing single images\n",
    "- Visualizing anomaly heatmaps\n",
    "- Batch processing multiple images\n",
    "- Interpreting detection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, make sure you're running this notebook from the MuSc directory and have installed the package:\n",
    "\n",
    "```bash\n",
    "cd MuSc\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) == 'examples':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Add MuSc to path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration\n",
    "\n",
    "The MuSc model is configured via a YAML file. Here we'll create a configuration programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    \"datasets\": {\n",
    "        \"img_resize\": 224,           # Input image size\n",
    "        \"dataset_name\": \"mvtec_ad\",  # Dataset type (for benchmark evaluation)\n",
    "        \"class_name\": \"ALL\",         # Category filter\n",
    "        \"divide_num\": 1,             # Dataset splitting\n",
    "        \"data_path\": \"./data/\",      # Dataset root\n",
    "    },\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "    \"models\": {\n",
    "        \"backbone_name\": \"dinov2_vitb14\",  # Vision transformer backbone\n",
    "        \"batch_size\": 1,\n",
    "        \"feature_layers\": [11],            # Transformer layers to use\n",
    "        \"pretrained\": \"openai\",\n",
    "        \"r_list\": [1],                     # LNAMD aggregation radii\n",
    "    },\n",
    "    \"testing\": {\n",
    "        \"output_dir\": \"output_notebook\",\n",
    "        \"vis\": False,\n",
    "        \"vis_type\": \"single_norm\",\n",
    "        \"save_excel\": False,\n",
    "    },\n",
    "    \"thresholds\": {\n",
    "        \"image_threshold\": 9.0,    # Detection threshold (1.0-10.0)\n",
    "        \"overlay_threshold\": 3.5,  # Visualization intensity\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Backbone: {config['models']['backbone_name']}\")\n",
    "print(f\"  Image size: {config['datasets']['img_resize']}\")\n",
    "print(f\"  Device: {config['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Model\n",
    "\n",
    "Loading the model for the first time will download pre-trained weights (~1-2 GB). This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.musc import MuSc\n",
    "\n",
    "print(\"Loading MuSc model (this may download weights on first run)...\")\n",
    "model = MuSc(config)\n",
    "print(f\"Model loaded on device: {model.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess an Image\n",
    "\n",
    "Let's create a helper function to load and preprocess images for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size=224):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image for MuSc inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        target_size: Size to resize the image to\n",
    "    \n",
    "    Returns:\n",
    "        original: Original image (BGR)\n",
    "        tensor: Preprocessed tensor [1, 3, H, W]\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    original = cv2.imread(image_path)\n",
    "    if original is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    # Convert BGR to RGB and resize\n",
    "    img_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (target_size, target_size))\n",
    "    \n",
    "    # Normalize to [0, 1] and convert to tensor\n",
    "    img_norm = img_resized.astype(np.float32) / 255.0\n",
    "    tensor = torch.tensor(img_norm).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    return original, tensor\n",
    "\n",
    "def create_synthetic_image(size=224, has_defect=False):\n",
    "    \"\"\"\n",
    "    Create a synthetic test image.\n",
    "    \n",
    "    Args:\n",
    "        size: Image dimensions\n",
    "        has_defect: If True, add a synthetic defect\n",
    "    \n",
    "    Returns:\n",
    "        original: Image as numpy array (BGR)\n",
    "        tensor: Preprocessed tensor\n",
    "    \"\"\"\n",
    "    # Create a simple pattern (like a product surface)\n",
    "    np.random.seed(42)\n",
    "    img = np.ones((size, size, 3), dtype=np.uint8) * 180  # Gray background\n",
    "    \n",
    "    # Add some texture\n",
    "    noise = np.random.randint(0, 20, (size, size, 3), dtype=np.uint8)\n",
    "    img = cv2.add(img, noise)\n",
    "    \n",
    "    if has_defect:\n",
    "        # Add a \"defect\" - a dark spot\n",
    "        center = (size // 3, size // 2)\n",
    "        cv2.circle(img, center, 15, (50, 50, 50), -1)\n",
    "        cv2.circle(img, center, 20, (100, 100, 100), 2)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    img_norm = img.astype(np.float32) / 255.0\n",
    "    tensor = torch.tensor(img_norm).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    return img, tensor\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Inference on Synthetic Images\n",
    "\n",
    "Let's test the model with synthetic \"normal\" and \"defective\" images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test images\n",
    "normal_img, normal_tensor = create_synthetic_image(has_defect=False)\n",
    "defect_img, defect_tensor = create_synthetic_image(has_defect=True)\n",
    "\n",
    "# Display the images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(cv2.cvtColor(normal_img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(\"Normal Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(defect_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(\"Image with Defect\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print(\"Running inference on both images...\")\n",
    "\n",
    "# Process both images as a batch\n",
    "batch_tensor = torch.cat([normal_tensor, defect_tensor], dim=0)\n",
    "batch_tensor = batch_tensor.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    anomaly_maps = model.infer_on_images([batch_tensor])\n",
    "\n",
    "print(f\"Anomaly maps shape: {anomaly_maps.shape}\")\n",
    "\n",
    "# Get scores\n",
    "normal_score = anomaly_maps[0].max()\n",
    "defect_score = anomaly_maps[1].max()\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Normal image max score: {normal_score:.4f}\")\n",
    "print(f\"  Defect image max score: {defect_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Anomaly Heatmaps\n",
    "\n",
    "Let's create a visualization function to display the anomaly maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_anomaly(image, anomaly_map, title=\"Anomaly Detection\", threshold=0.9):\n",
    "    \"\"\"\n",
    "    Visualize an anomaly map overlaid on the original image.\n",
    "    \n",
    "    Args:\n",
    "        image: Original image (BGR numpy array)\n",
    "        anomaly_map: 2D anomaly scores [H, W]\n",
    "        title: Plot title\n",
    "        threshold: Score threshold for anomaly classification\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Anomaly heatmap\n",
    "    heatmap = cv2.resize(anomaly_map, (image.shape[1], image.shape[0]))\n",
    "    im = axes[1].imshow(heatmap, cmap='jet', vmin=0, vmax=1)\n",
    "    axes[1].set_title(f\"Anomaly Map (max: {anomaly_map.max():.3f})\")\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
    "    \n",
    "    # Overlay\n",
    "    heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(image, 0.6, heatmap_colored, 0.4, 0)\n",
    "    axes[2].imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Add detection result\n",
    "    max_score = anomaly_map.max()\n",
    "    status = \"ANOMALY\" if max_score > threshold else \"OK\"\n",
    "    color = \"red\" if max_score > threshold else \"green\"\n",
    "    axes[2].set_title(f\"Overlay - {status}\", color=color)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "visualize_anomaly(normal_img, anomaly_maps[0], \"Normal Sample\")\n",
    "visualize_anomaly(defect_img, anomaly_maps[1], \"Defective Sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processing Real Images\n",
    "\n",
    "If you have real images to test, place them in the `sample_data/` directory and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process images from sample_data directory\n",
    "sample_dir = \"sample_data\"\n",
    "\n",
    "if os.path.exists(sample_dir):\n",
    "    # Find all images\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(sample_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                image_files.append(os.path.join(root, f))\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {sample_dir}\")\n",
    "    \n",
    "    # Process first few images\n",
    "    for img_path in image_files[:5]:\n",
    "        try:\n",
    "            original, tensor = load_image(img_path, config['datasets']['img_resize'])\n",
    "            tensor = tensor.to(model.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                anomaly_map = model.infer_on_images([tensor])\n",
    "            \n",
    "            visualize_anomaly(original, anomaly_map[0], os.path.basename(img_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "else:\n",
    "    print(f\"No {sample_dir}/ directory found.\")\n",
    "    print(\"To test with real images:\")\n",
    "    print(\"  1. Create sample_data/ directory\")\n",
    "    print(\"  2. Add some test images\")\n",
    "    print(\"  3. Re-run this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Understanding the Scores\n",
    "\n",
    "The anomaly score is a value between 0 and 1:\n",
    "- **0**: Perfectly normal\n",
    "- **1**: Highly anomalous\n",
    "\n",
    "The threshold determines what gets flagged as anomalous:\n",
    "- **Higher threshold** (0.9-1.0): Fewer false positives, only obvious defects\n",
    "- **Lower threshold** (0.5-0.7): More sensitive, may have false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different thresholds\n",
    "thresholds = [0.5, 0.7, 0.9, 0.95]\n",
    "\n",
    "print(\"Classification results at different thresholds:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    normal_result = \"ANOMALY\" if normal_score > thresh else \"OK\"\n",
    "    defect_result = \"ANOMALY\" if defect_score > thresh else \"OK\"\n",
    "    \n",
    "    print(f\"\\nThreshold: {thresh}\")\n",
    "    print(f\"  Normal image: {normal_result} (score: {normal_score:.4f})\")\n",
    "    print(f\"  Defect image: {defect_result} (score: {defect_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using Different Backbone Models\n",
    "\n",
    "MuSc supports multiple vision transformer backbones. Here's how to switch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available backbones (uncomment one to test)\n",
    "available_backbones = [\n",
    "    # Fast (for real-time)\n",
    "    \"vit_tiny_patch16_224.augreg_in21k\",\n",
    "    \"dino_deitsmall16\",\n",
    "    \n",
    "    # Balanced (recommended)\n",
    "    \"dinov2_vitb14\",  # <- Default\n",
    "    \"ViT-B-16\",\n",
    "    \n",
    "    # High accuracy (slower)\n",
    "    \"dinov2_vitl14\",\n",
    "    \"ViT-L-14\",\n",
    "]\n",
    "\n",
    "print(\"Available backbone models:\")\n",
    "for backbone in available_backbones:\n",
    "    print(f\"  - {backbone}\")\n",
    "\n",
    "print(\"\\nTo use a different backbone, modify config['models']['backbone_name']\")\n",
    "print(\"and reinitialize the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exporting Results\n",
    "\n",
    "Here's how to save detection results programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_results(results, output_path):\n",
    "    \"\"\"\n",
    "    Export detection results to JSON.\n",
    "    \n",
    "    Args:\n",
    "        results: List of detection results\n",
    "        output_path: Path to save JSON file\n",
    "    \"\"\"\n",
    "    export_data = {\n",
    "        \"export_time\": datetime.now().isoformat(),\n",
    "        \"model_config\": {\n",
    "            \"backbone\": config['models']['backbone_name'],\n",
    "            \"image_size\": config['datasets']['img_resize'],\n",
    "        },\n",
    "        \"results\": results,\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "# Example: Export our test results\n",
    "results = [\n",
    "    {\n",
    "        \"image\": \"normal_synthetic\",\n",
    "        \"max_score\": float(normal_score),\n",
    "        \"is_anomaly\": bool(normal_score > 0.9),\n",
    "    },\n",
    "    {\n",
    "        \"image\": \"defect_synthetic\",\n",
    "        \"max_score\": float(defect_score),\n",
    "        \"is_anomaly\": bool(defect_score > 0.9),\n",
    "    },\n",
    "]\n",
    "\n",
    "export_results(results, \"output_notebook/detection_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. **Configure** the MuSc model with different settings\n",
    "2. **Load** images and preprocess them for inference\n",
    "3. **Run inference** to detect anomalies\n",
    "4. **Visualize** anomaly heatmaps\n",
    "5. **Interpret** detection scores\n",
    "6. **Export** results for further analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try the GUI: `musc-gui` for real-time detection\n",
    "- Try the CLI: `python demo.py --input your_image.png`\n",
    "- Read the documentation in `README.md` and `ARCHITECTURE.md`\n",
    "- Explore different backbone models for your use case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
